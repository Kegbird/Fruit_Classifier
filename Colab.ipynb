{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "msa_project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zTLHdonjkK-"
      },
      "source": [
        "Required dependecies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsuRfV1NvUj-"
      },
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install --upgrade tensorflow\n",
        "!pip install numpy --upgrade\n",
        "!pip install -q kaggle\n",
        "!pip install zipfile36"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9W14MrTzpJ9m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24aa35d0-ba42-4564-f5f6-2ee97597d4e9"
      },
      "source": [
        "!mkdir checkpoints\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d moltean/fruits"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading fruits.zip to /content\n",
            " 99% 1.28G/1.28G [00:42<00:00, 65.5MB/s]\n",
            "100% 1.28G/1.28G [00:43<00:00, 32.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKRZD2zyzITa"
      },
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('fruits.zip', 'r') as zipObj:\n",
        "   zipObj.extractall()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kelrBPQH-LM5"
      },
      "source": [
        "# **Extraction of types from \"fruits-360\" dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNGZsWXl-KxR"
      },
      "source": [
        "!mkdir fruits-360-type\n",
        "!mkdir fruits-360-type/Test\n",
        "!mkdir fruits-360-type/Training\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "soruce_dir_test=\"fruits-360_dataset/fruits-360/Test/\"\n",
        "soruce_dir_training=\"fruits-360_dataset/fruits-360/Training/\"\n",
        "test_dir=\"fruits-360-type/Test/\"\n",
        "train_dir=\"fruits-360-type/Training/\"\n",
        "\n",
        "def extract_types(directory, destination):\n",
        "  type_counter={'apple':0,'banana':0,'cherry':0,'grape':0,'peach':0,'pear':0,'pepper':0,'plum':0,'potato':0,'tomato':0}\n",
        "  for label_type in ['apple','banana','cherry','grape','peach','pear','pepper','plum','potato','tomato']:\n",
        "    for label_variety in os.listdir(directory):\n",
        "      if(label_variety.lower().find(label_type)==0 and label_variety.lower().find(\"grapefruit\")!=0):\n",
        "          image_list=os.listdir(os.path.join(directory,label_variety))\n",
        "          for image in image_list:\n",
        "              shutil.copy(os.path.join(directory,label_variety,image), os.path.join(destination,label_type,f\"{label_type}_{type_counter[label_type]}.jpg\"))\n",
        "              type_counter[label_type]+=1\n",
        "      else:\n",
        "        continue\n",
        "\n",
        "for label in ['apple','banana','cherry','grape','peach','pear','pepper','plum','potato','tomato']:\n",
        "  os.system(f\"mkdir {os.path.join(test_dir,label)}\")\n",
        "  os.system(f\"mkdir {os.path.join(train_dir,label)}\")\n",
        "\n",
        "extract_types(soruce_dir_test, test_dir)\n",
        "extract_types(soruce_dir_training, train_dir)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Modules"
      ],
      "metadata": {
        "id": "MsUpExMM-ZBg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten, Dropout"
      ],
      "metadata": {
        "id": "OYlSq6b7-YMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0ABOgHN2PkQ"
      },
      "source": [
        "# **Classification based on fruit and vegetable types**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxMP49lr2aqY",
        "outputId": "f6bd0035-b70e-435c-9d49-8c19ce70ff18"
      },
      "source": [
        "\n",
        "\n",
        "train_data=[]\n",
        "train_label=[]\n",
        "test_data=[]\n",
        "test_label=[]\n",
        "epochs=10\n",
        "batch_size=16\n",
        "optimizer=\"adam\"\n",
        "img_size = (32, 32)\n",
        "shape = (32, 32, 3)\n",
        "test_dir = 'fruits-360-type/Test'\n",
        "train_dir = 'fruits-360-type/Training'\n",
        "metrics=['accuracy']\n",
        "\n",
        "labels = os.listdir(train_dir)\n",
        "num_classes = len(labels)\n",
        "\n",
        "def calculate_class_weights(train_label):\n",
        "    train_size=len(train_label)\n",
        "    weights={}\n",
        "    for i in range(10):\n",
        "        weights[i]=0\n",
        "    for i in train_label:\n",
        "        weights[i]=weights[i]+1\n",
        "    for i in range(num_classes):\n",
        "        weights[i]=train_size/(weights[i]*2.)\n",
        "    return weights\n",
        "\n",
        "def load_data(dir):\n",
        "    i=0\n",
        "    data=[]\n",
        "    data_label=[]\n",
        "    for label in labels:\n",
        "        images=os.listdir(os.path.join(dir,label))\n",
        "        for image in images:\n",
        "            image_path=os.path.join(dir,label,image)\n",
        "            image=load_img(image_path,color_mode='rgb', target_size=img_size)\n",
        "            array_image=img_to_array(image)\n",
        "            array_image=array_image/255.0\n",
        "            data.append(array_image)\n",
        "            data_label.append(i)\n",
        "        i=i+1\n",
        "    tmp=list(zip(data, data_label))\n",
        "    data, data_label=zip(*tmp)\n",
        "    return data, data_label\n",
        "\n",
        "print(\"Loading training images...\")\n",
        "train_data, train_label=load_data(train_dir)\n",
        "train_data=np.array(train_data)\n",
        "train_label=np.array(train_label)\n",
        "print(\"Loading test images...\")\n",
        "test_data, test_label=load_data(test_dir)\n",
        "test_data=np.array(test_data)\n",
        "test_label=np.array(test_label)\n",
        "network=tf.keras.models.Sequential()\n",
        "network.add(Input(shape=shape))\n",
        "network.add(Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\", strides=(1, 1)))\n",
        "network.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "network.add(Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\", strides=(1, 1)))\n",
        "network.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "network.add(Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\", strides=(1, 1)))\n",
        "network.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "network.add(Flatten())\n",
        "network.add(Dense(512, activation=\"softmax\"))\n",
        "network.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=metrics)\n",
        "print(network.summary())\n",
        "weights=calculate_class_weights(train_label)\n",
        "history = network.fit(x=train_data,y=train_label,\n",
        "                      batch_size=batch_size,\n",
        "                      epochs=epochs,\n",
        "                      verbose=1)\n",
        "train_loss, train_accuracy = network.evaluate(x=train_data,y=train_label,steps=(len(train_data)//batch_size)+1, verbose=1)\n",
        "test_loss, test_accuracy = network.evaluate(x=test_data, y=test_label,steps=(len(test_data)//batch_size)+1, verbose=1)\n",
        "print(f\"Train accuracy = {train_accuracy}\")\n",
        "print(f\"Test accuracy = {test_accuracy}\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading training images...\n",
            "Loading test images...\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 8, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 4, 4, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               1049088   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,142,336\n",
            "Trainable params: 1,142,336\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "2038/2038 [==============================] - 25s 7ms/step - loss: 0.2785 - accuracy: 0.9110\n",
            "Epoch 2/10\n",
            "2038/2038 [==============================] - 14s 7ms/step - loss: 0.0189 - accuracy: 0.9944\n",
            "Epoch 3/10\n",
            "2038/2038 [==============================] - 15s 7ms/step - loss: 0.0111 - accuracy: 0.9967\n",
            "Epoch 4/10\n",
            "2038/2038 [==============================] - 14s 7ms/step - loss: 0.0184 - accuracy: 0.9949\n",
            "Epoch 5/10\n",
            "2038/2038 [==============================] - 14s 7ms/step - loss: 0.0067 - accuracy: 0.9982\n",
            "Epoch 6/10\n",
            "2038/2038 [==============================] - 14s 7ms/step - loss: 3.8275e-05 - accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "2038/2038 [==============================] - 14s 7ms/step - loss: 0.0164 - accuracy: 0.9957\n",
            "Epoch 8/10\n",
            "2038/2038 [==============================] - 14s 7ms/step - loss: 0.0031 - accuracy: 0.9993\n",
            "Epoch 9/10\n",
            "2038/2038 [==============================] - 14s 7ms/step - loss: 3.2110e-05 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "2038/2038 [==============================] - 15s 7ms/step - loss: 7.9446e-06 - accuracy: 1.0000\n",
            "2038/2038 [==============================] - 9s 4ms/step - loss: 4.2164e-06 - accuracy: 1.0000\n",
            "682/682 [==============================] - 3s 4ms/step - loss: 0.0362 - accuracy: 0.9881\n",
            "Train accuracy = 1.0\n",
            "Test accuracy = 0.9880799651145935\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5uDAotI_YZz"
      },
      "source": [
        "# **Classification based on fruit and vegetable varieties**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfV5tglGDzDY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "314a6b31-d81f-419d-d24d-03a61d7e492b"
      },
      "source": [
        "train_data=[]\n",
        "train_label=[]\n",
        "test_data=[]\n",
        "test_label=[]\n",
        "epochs=20\n",
        "batch_size=16\n",
        "optimizer=\"adam\"\n",
        "img_size = (32, 32)\n",
        "shape = (32, 32, 3)\n",
        "test_dir = 'fruits-360_dataset/fruits-360/Test'\n",
        "train_dir = 'fruits-360_dataset/fruits-360/Training'\n",
        "metrics=['accuracy']\n",
        "\n",
        "labels = os.listdir(train_dir)\n",
        "print(labels)\n",
        "num_classes = len(labels)\n",
        "\n",
        "def calculate_class_weights(train_label, num_classes):\n",
        "    train_size=len(train_label)\n",
        "    weights={}\n",
        "    for i in range(num_classes):\n",
        "        weights[i]=0\n",
        "    for i in train_label:\n",
        "        weights[i]=weights[i]+1\n",
        "    for i in range(num_classes):\n",
        "        weights[i]=train_size/(weights[i]*2.)\n",
        "    return weights\n",
        "\n",
        "def load_data(dir, labels):\n",
        "    i=0\n",
        "    data=[]\n",
        "    data_label=[]\n",
        "    for label in labels:\n",
        "        images=os.listdir(os.path.join(dir,label))\n",
        "        for image in images:\n",
        "            image_path=os.path.join(dir,label,image)\n",
        "            image=load_img(image_path,color_mode='rgb', target_size=img_size)\n",
        "            array_image=img_to_array(image)\n",
        "            array_image=array_image/255.0\n",
        "            data.append(array_image)\n",
        "            data_label.append(i)\n",
        "        i=i+1\n",
        "    tmp=list(zip(data, data_label))\n",
        "    data, data_label=zip(*tmp)\n",
        "    return data, data_label\n",
        "\n",
        "print(\"Loading training images...\")\n",
        "train_data, train_label=load_data(train_dir, labels)\n",
        "train_data=np.array(train_data)\n",
        "train_label=np.array(train_label)\n",
        "print(\"Loading test images...\")\n",
        "test_data, test_label=load_data(test_dir, labels)\n",
        "test_data=np.array(test_data)\n",
        "test_label=np.array(test_label)\n",
        "network=tf.keras.models.Sequential()\n",
        "network.add(Input(shape=shape))\n",
        "network.add(Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\", strides=(1, 1)))\n",
        "network.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "network.add(Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\", strides=(1, 1)))\n",
        "network.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "network.add(Flatten())\n",
        "network.add(Dense(512, activation=\"relu\"))\n",
        "network.add(Dropout(0.5))\n",
        "network.add(Dense(num_classes, activation=\"softmax\"))\n",
        "network.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=metrics)\n",
        "print(network.summary())\n",
        "weights=calculate_class_weights(train_label, num_classes)\n",
        "history = network.fit(x=train_data,y=train_label,\n",
        "                        batch_size=batch_size,\n",
        "                        epochs=epochs,\n",
        "                        class_weight=weights,\n",
        "                        verbose=1)\n",
        "train_loss, train_accuracy = network.evaluate(x=train_data,y=train_label, verbose=1)\n",
        "test_loss, test_accuracy = network.evaluate(x=test_data, y=test_label, verbose=1)\n",
        "predicted=network.predict(test_data, batch_size=16, verbose=1)\n",
        "predicted = predicted.argmax(axis=-1)\n",
        "print(f\"Train accuracy = {train_accuracy}\")\n",
        "print(f\"Test accuracy = {test_accuracy}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Kiwi', 'Melon Piel de Sapo', 'Eggplant', 'Pear Williams', 'Chestnut', 'Cherry Wax Black', 'Huckleberry', 'Pear Abate', 'Clementine', 'Pear Red', 'Lychee', 'Cocos', 'Mango', 'Granadilla', 'Avocado', 'Corn Husk', 'Peach Flat', 'Banana Lady Finger', 'Passion Fruit', 'Pear 2', 'Potato Red Washed', 'Nectarine', 'Orange', 'Cherry Wax Yellow', 'Cauliflower', 'Maracuja', 'Mandarine', 'Nut Forest', 'Mango Red', 'Apple Golden 3', 'Apple Braeburn', 'Apple Red Yellow 1', 'Tomato 1', 'Watermelon', 'Pitahaya Red', 'Kaki', 'Cherry 2', 'Strawberry Wedge', 'Guava', 'Tomato Heart', 'Corn', 'Nut Pecan', 'Peach 2', 'Limes', 'Banana Red', 'Tomato Yellow', 'Grape White 4', 'Grape Blue', 'Pineapple Mini', 'Pear Stone', 'Grape White 3', 'Tomato not Ripened', 'Tangelo', 'Potato Red', 'Ginger Root', 'Kohlrabi', 'Onion Red Peeled', 'Pepper Yellow', 'Plum 2', 'Pepper Red', 'Walnut', 'Apricot', 'Onion Red', 'Pear', 'Raspberry', 'Cucumber Ripe', 'Cactus fruit', 'Lemon Meyer', 'Tomato 4', 'Pepino', 'Cucumber Ripe 2', 'Cherry 1', 'Grape White 2', 'Onion White', 'Apple Golden 1', 'Blueberry', 'Potato Sweet', 'Redcurrant', 'Peach', 'Cantaloupe 1', 'Banana', 'Apple Red Yellow 2', 'Beetroot', 'Strawberry', 'Plum 3', 'Papaya', 'Dates', 'Apple Red 2', 'Grape White', 'Physalis', 'Apple Granny Smith', 'Avocado ripe', 'Tomato 3', 'Rambutan', 'Pear Monster', 'Carambula', 'Salak', 'Apple Crimson Snow', 'Apple Pink Lady', 'Pepper Green', 'Plum', 'Tomato 2', 'Apple Red Delicious', 'Kumquats', 'Cherry Rainier', 'Nectarine Flat', 'Grape Pink', 'Cherry Wax Red', 'Pear Kaiser', 'Fig', 'Grapefruit White', 'Pomelo Sweetie', 'Tomato Maroon', 'Hazelnut', 'Apple Golden 2', 'Apple Red 1', 'Pepper Orange', 'Grapefruit Pink', 'Physalis with Husk', 'Potato White', 'Tamarillo', 'Mangostan', 'Pineapple', 'Apple Red 3', 'Pear Forelle', 'Tomato Cherry Red', 'Pomegranate', 'Mulberry', 'Quince', 'Lemon', 'Cantaloupe 2']\n",
            "Loading training images...\n",
            "Loading test images...\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_5 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 16, 16, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 8, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 512)               2097664   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 131)               67203     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,184,259\n",
            "Trainable params: 2,184,259\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/20\n",
            "4231/4231 [==============================] - 30s 7ms/step - loss: 38.5723 - accuracy: 0.8377\n",
            "Epoch 2/20\n",
            "4231/4231 [==============================] - 30s 7ms/step - loss: 6.1971 - accuracy: 0.9701\n",
            "Epoch 3/20\n",
            "4231/4231 [==============================] - 31s 7ms/step - loss: 4.5828 - accuracy: 0.9794\n",
            "Epoch 4/20\n",
            "4231/4231 [==============================] - 30s 7ms/step - loss: 3.6678 - accuracy: 0.9831\n",
            "Epoch 5/20\n",
            "4231/4231 [==============================] - 30s 7ms/step - loss: 3.1450 - accuracy: 0.9870\n",
            "Epoch 6/20\n",
            "4231/4231 [==============================] - 30s 7ms/step - loss: 2.8773 - accuracy: 0.9881\n",
            "Epoch 7/20\n",
            "4231/4231 [==============================] - 30s 7ms/step - loss: 2.6481 - accuracy: 0.9889\n",
            "Epoch 8/20\n",
            "4231/4231 [==============================] - 30s 7ms/step - loss: 2.3012 - accuracy: 0.9912\n",
            "Epoch 9/20\n",
            "4231/4231 [==============================] - 30s 7ms/step - loss: 2.2768 - accuracy: 0.9916\n",
            "Epoch 10/20\n",
            "4231/4231 [==============================] - 30s 7ms/step - loss: 2.2120 - accuracy: 0.9926\n",
            "Epoch 11/20\n",
            "4231/4231 [==============================] - 30s 7ms/step - loss: 1.9573 - accuracy: 0.9927\n",
            "Epoch 12/20\n",
            "4231/4231 [==============================] - 30s 7ms/step - loss: 2.1271 - accuracy: 0.9935\n",
            "Epoch 13/20\n",
            "4231/4231 [==============================] - 30s 7ms/step - loss: 2.2086 - accuracy: 0.9931\n",
            "Epoch 14/20\n",
            "4231/4231 [==============================] - 30s 7ms/step - loss: 2.1034 - accuracy: 0.9931\n",
            "Epoch 15/20\n",
            "4231/4231 [==============================] - 30s 7ms/step - loss: 2.0698 - accuracy: 0.9940\n",
            "Epoch 16/20\n",
            "4231/4231 [==============================] - 30s 7ms/step - loss: 1.9629 - accuracy: 0.9945\n",
            "Epoch 17/20\n",
            "4231/4231 [==============================] - 30s 7ms/step - loss: 2.0355 - accuracy: 0.9944\n",
            "Epoch 18/20\n",
            "4231/4231 [==============================] - 30s 7ms/step - loss: 2.1734 - accuracy: 0.9947\n",
            "Epoch 19/20\n",
            "4231/4231 [==============================] - 30s 7ms/step - loss: 1.9340 - accuracy: 0.9951\n",
            "Epoch 20/20\n",
            "4231/4231 [==============================] - 30s 7ms/step - loss: 2.3614 - accuracy: 0.9949\n",
            "2116/2116 [==============================] - 11s 5ms/step - loss: 1.3447e-04 - accuracy: 0.9999\n",
            "709/709 [==============================] - 4s 5ms/step - loss: 0.3049 - accuracy: 0.9759\n",
            "1418/1418 [==============================] - 3s 2ms/step\n",
            "Train accuracy = 0.9999409317970276\n",
            "Test accuracy = 0.9759343862533569\n"
          ]
        }
      ]
    }
  ]
}